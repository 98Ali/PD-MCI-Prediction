{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4ZBmbTYIIKCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier,BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.impute import SimpleImputer\n",
        "import warnings\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV,StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_selection import SelectKBest, f_classif,chi2, mutual_info_classif\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "import random\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statistics\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, metrics, model_selection, svm\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from scipy import stats\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n"
      ],
      "metadata": {
        "id": "zf1tkOYim8CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_param_space = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "abc_param_space = {\n",
        "    'n_estimators': [10, 50],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'algorithm': ['SAMME', 'SAMME.R']\n",
        "}\n",
        "\n",
        "lr_param_space = {\n",
        "    'penalty': ['l2', 'none'],\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "rf_param_space = {\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 4],\n",
        "    'max_features': ['sqrt', 'log2']}\n",
        "\n",
        "dt_param_space = {\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 4],\n",
        "    'max_features': ['sqrt', 'log2']}\n",
        "svc_param_space = {\n",
        "    'C': [0.001, 0.1, 1],\n",
        "    'kernel': ['linear', 'sigmoid'],\n",
        "    'degree': [3, 5],\n",
        "    'probability':[True]\n",
        "}\n",
        "gb_param_space = {\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 4],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "bg_param_space = {\n",
        "    'n_estimators': [10, 50],\n",
        "}\n",
        "\n",
        "mlp_param_space = {\n",
        "    'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
        "    'max_iter' : [100],\n",
        "    'activation' :['logistic', 'tanh', 'relu']\n",
        "}\n",
        "classifiers = {\n",
        "    'MLP' : (MLPClassifier() , mlp_param_space),\n",
        "    'DecisionTreeClassifier' :(DecisionTreeClassifier(), dt_param_space),\n",
        "    'RandomForestClassifier':(RandomForestClassifier(), rf_param_space),\n",
        "    'KNeighborsClassifier': (KNeighborsClassifier(), knn_param_space),\n",
        "    'AdaBoostClassifier': (AdaBoostClassifier(), abc_param_space),\n",
        "    'LogisticRegression': (LogisticRegression(), lr_param_space),\n",
        "    'SVC': (SVC(), svc_param_space),\n",
        "    'Bagging' : (BaggingClassifier(),bg_param_space),\n",
        "    'GradientBoosting': (GradientBoostingClassifier(),gb_param_space)\n",
        "    }"
      ],
      "metadata": {
        "id": "VKakJo6igFKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rand_test(dataX,dataY,percent,seed,outcome):\n",
        "\n",
        "  indics_y_cl1 = dataY[dataY[outcome]==0].index.to_list()\n",
        "\n",
        "  perc_cl = round(dataX.shape[0]*percent/2)\n",
        "\n",
        "  random.seed(seed)\n",
        "\n",
        "  indics_y_rand_cl1 = random.sample(indics_y_cl1, perc_cl)\n",
        "\n",
        "  indics_y_cl2 = dataY[dataY[outcome]==1].index.to_list()\n",
        "  indics_y_rand_cl2 = random.sample(indics_y_cl2, perc_cl)\n",
        "\n",
        "  rand_y_cl1 = dataY.loc[indics_y_rand_cl1]\n",
        "  rand_y_cl2 = dataY.loc[indics_y_rand_cl2]\n",
        "\n",
        "  rand_x_cl1 = dataX.loc[indics_y_rand_cl1]\n",
        "  rand_x_cl2 = dataX.loc[indics_y_rand_cl2]\n",
        "\n",
        "  test_y = pd.concat([rand_y_cl1,rand_y_cl2],axis=0)\n",
        "  test_x = pd.concat([rand_x_cl1,rand_x_cl2],axis=0)\n",
        "\n",
        "  train_x = dataX.drop(indics_y_rand_cl1)\n",
        "  train_x = train_x.drop(indics_y_rand_cl2)\n",
        "\n",
        "  train_y = dataY.drop(indics_y_rand_cl1)\n",
        "  train_y = train_y.drop(indics_y_rand_cl2)\n",
        "\n",
        "  return test_x, test_y, train_x, train_y\n"
      ],
      "metadata": {
        "id": "AZHMgsef-f0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_path = \"/content/drive/MyDrive/Parkinson & Multiple labels project/Data/new/ci/\"\n",
        "result_path = \"/content/drive/MyDrive/Parkinson & Multiple labels project/Result/\"\n",
        "n_feats = [10,50,100]\n",
        "\n",
        "def append_row(df, row):\n",
        "    return pd.concat([\n",
        "                df,\n",
        "                pd.DataFrame([row], columns=row.index)]\n",
        "          ).reset_index(drop=True)\n",
        "datasets = ['deep_ds']\n",
        "# seeds = [2666, 524, 552, 380, 2170, 8848, 9738, 153, 8586, 7243, 1202, 3680, 3976, 691, 6386, 2748, 8890, 9340, 2707, 6891]\n",
        "seeds = [6891]"
      ],
      "metadata": {
        "id": "JzGxo1RZgGKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in datasets:\n",
        "  runs_df = pd.DataFrame()\n",
        "  path = feature_path+dataset+\".xlsx\"\n",
        "  X = pd.read_excel(path , sheet_name='Data' , engine='openpyxl' ,header=0).iloc[:,1:]\n",
        "  Y = pd.read_excel(path, sheet_name='Output' , engine='openpyxl',header=0).iloc[:,1:].iloc[:,4:]\n",
        "\n",
        "  imputer = SimpleImputer(missing_values= np.nan , strategy='mean')\n",
        "  X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "  a = []\n",
        "  scaler = StandardScaler()\n",
        "  X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "  a = Y.columns.to_list()\n",
        "  # a.reverse()\n",
        "  for outcome in a:\n",
        "    for name, (clf, param_space) in classifiers.items():\n",
        "      for n_feat in n_feats:\n",
        "        internals = []\n",
        "        externals = []\n",
        "        externals_auc = []\n",
        "        YL = pd.DataFrame(Y[outcome])\n",
        "\n",
        "        for seed in seeds:\n",
        "\n",
        "          smote = SMOTE(random_state=42)\n",
        "          X_train, y_train = smote.fit_resample(X, YL)\n",
        "\n",
        "          X_test, y_test, X_train, y_train = get_rand_test(X_train,y_train,0.2,seed,outcome)\n",
        "\n",
        "          rfe = RFE(LinearRegression(), n_features_to_select=n_feat)\n",
        "          X_train = rfe.fit_transform(X_train, y_train)\n",
        "          X_test = rfe.transform(X_test)\n",
        "\n",
        "          grid_search = GridSearchCV(clf, param_space, n_jobs=-1, cv=5)\n",
        "          grid_search.fit(X_train, y_train)\n",
        "\n",
        "          best_regressor = grid_search.best_estimator_\n",
        "\n",
        "          cv_results = cross_validate(best_regressor, X_train, y_train, cv=5, scoring='roc_auc', return_train_score = True)\n",
        "\n",
        "          valSC = statistics.mean(cv_results['test_score'])\n",
        "\n",
        "          y_test_pred = best_regressor.predict(X_test)\n",
        "          accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "          try:\n",
        "            auc_test = roc_auc_score(y_test, best_regressor.predict_proba(X_test)[:,1])\n",
        "          except:\n",
        "            auc_test = 'NaN'\n",
        "\n",
        "          print(str(seed) +' n_feat : '+str(n_feat)+' DS : '+dataset+' OUTCOME : ' +outcome+' , CLF : '+name+' , TRN : '+str(valSC)+' , TST ACC: '+str(auc_test) +' , TST AUC: '+str(accuracy_test) )\n",
        "        run_new_row = pd.Series({\"DS\" : dataset ,'n_feat' : n_feat , \"OUTCOME\" : outcome ,\"CLF\" : name\n",
        "                        ,\"TRN\":valSC\n",
        "                        ,\"TST\":accuracy_test,\"TST AUC\":auc_test})\n",
        "        runs_df = append_row(runs_df, run_new_row)\n",
        "\n",
        "runs_df.to_csv(result_path+dataset+\"_park-run18.csv\")"
      ],
      "metadata": {
        "id": "iZb1cR5t7n1a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}